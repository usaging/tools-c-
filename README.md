# 介绍

# procctl

服务程序的调度程序，周期性启动服务程序或shell脚本。

Using:./procctl timetvl program argv ...

fork子进程执行任务，父进程等待子进程退出，然后sleep一段时间，再次fork。

# checkproc

检查后台服务程序是否超时，如果已超时，就终止它。

Using:./checkproc logfilename

遍历共享内存中全部的进程记录，如果进程已超时，终止它。

# gzipfiles

用于压缩历史的数据文件或日志文件。

Using:./gzipfiles pathname matchstr timeout

本程序把pathname目录及子目录中timeout天之前的匹配matchstr文件全部压缩，timeout可以是小数。

# deletefiles

用于删除历史的数据文件或日志文件。

Using:./deletefiles pathname matchstr timeout

本程序把pathname目录及子目录中timeout天之前的匹配matchstr文件全部删除，timeout可以是小数。

# ftpputfiles

用于将本地文件上传到FTP服务器。

FTP简单通用，适用于内网传输。

## 关键组件

1. 参数结构体 (st_arg)

- 远程服务端的IP和端口
- 传输模式，1-被动模式，2-主动模式
- 远程服务端ftp的用户名
- 远程服务端ftp的密码
- 远程服务端存放文件的目录
- 本地文件存放的目录
- 待上传文件匹配的规则
- 上传后客户端文件的处理方式
- 上传后客户端文件的备份目录
- 已上传成功文件名清单
- 进程心跳的超时时间
- 进程名

2. 核心容器
map<string, string> mfromok: 存放已上传成功文件的信息

list<struct st_fileinfo> vfromdir: 本地目录中的文件列表

list<struct st_fileinfo> vtook: 本次不需要上传的文件

list<struct st_fileinfo> vupload: 本次需要上传的文件

3. 核心函数

loadlocalfile(): 加载本地文件列表

loadokfile(): 加载已上传成功文件信息

compmap(): 比较文件列表，确定需要上传的文件

writetookfile(): 写入已上传文件信息

appendtookfile(): 追加上传成功的文件记录

## 核心工作流程

1. FTP连接和认证
   
2. 获取本地文件列表

3. 增量上传处理（ptype=1）

加载已上传文件信息到容器mfromok。

比较文件列表，确定需要上传的文件。

更新已上传文件信息。

4. 文件上传

遍历需要上传的文件列表。

拼接本地和远程文件路径。

使用ftp.put()方法上传文件。

处理上传后的本地文件（根据ptype参数）。

ptype=1: 记录已上传文件信息。

ptype=2: 删除本地文件。

ptype=3: 将本地文件移动到备份目录。

# ftpgetfiles

用于从FTP服务器下载文件到本地目录。

## 关键组件

1. 参数结构体 (st_arg)

- 远程服务端的IP和端口
- 传输模式，1-被动模式，2-主动模式
- 远程服务端ftp的用户名
- 远程服务端ftp的密码
- 远程服务端存放文件的目录
- 本地文件存放的目录
- 待下载文件匹配的规则
- 下载后服务端文件的处理方式
- 下载后服务端文件的备份目录
- 已下载成功文件信息存放的文件
- 是否需要检查服务端文件的时间
- 进程心跳超时的时间
- 进程名

1. 核心容器

map<string, string> mfromok: 存放已下载成功文件的信息。

list<struct st_fileinfo> vfromnlist: 下载前列出服务端文件名的容器。

list<struct st_fileinfo> vtook: 本次不需要下载的文件的容器。

list<struct st_fileinfo> vdownload: 本次需要下载的文件的容器。

3. 核心函数
   
loadokfile(): 加载已下载成功文件信息。

loadlistfile(): 加载FTP服务器文件列表。

compmap(): 比较文件列表，确定需要下载的文件。

writetookfile(): 写入已下载文件信息。

appendtookfile(): 追加下载成功的文件记录。

## 核心工作流程

1. 初始化阶段

2. FTP连接和认证

登录FTP服务器

切换到远程目录

3. 获取文件列表

使用ftp.nlist()方法获取服务器文件列表

将文件列表保存到本地临时文件

加载文件列表到容器vfromnlist

4. 增量下载处理（ptype=1）

加载已下载文件信息到容器mfromok

比较文件列表，确定需要下载的文件

更新已下载文件信息

5. 文件下载

遍历需要下载的文件列表

拼接远程和本地文件路径

使用ftp.get()方法下载文件

处理下载后的文件（根据ptype参数）

ptype=1: 记录已下载文件信息

ptype=2: 删除服务器上的文件

ptype=3: 将服务器文件移动到备份目录

# tcpputfiles

采用tcp协议，实现文件上传的客户端。

TCP传输文件比FTP效率更高。

## 核心工作流程

- 初始化：解析参数、连接服务器、登录认证。

- 循环执行：

扫描本地目录，获取文件列表。

遍历文件列表，逐个上传文件。

发送文件信息（元数据）。

发送文件内容（数据）。

接收并处理服务器的确认报文。

根据确认结果和处理策略（ptype）删除或移动本地文件。

- 心跳保活：在空闲时间间隔内，与服务器保持心跳连接，确保链路通畅。

## 关键组件分析

1. 参数结构 (st_arg)

该结构体定义了程序运行的所有配置，是其灵活性的核心：

- clienttype: 客户端类型（固定为1，上传）。
- ip & port: 服务器地址。
- clientpath & andchild & matchname: 定义从哪里、上传什么文件。（源）
- srvpath: 文件上传到服务器的哪个目录。（目标）
- ptype & clientpathbak: 定义文件上传成功后如何处理。（后续动作）
- timetvl: 控制执行任务的频率。
- timeout & pname: 用于进程心跳和监控。

2. 网络通信 (ctcpclient tcpclient)

封装了 TCP 客户端的基础操作（连接、读写）。

程序在整个生命周期内保持一个长连接，避免了频繁建立连接的开销。

3. 协议设计

程序与服务器之间设计了一个简单的应用层协议，用于协调文件传输：

a.登录阶段

客户端发送： 完整的参数 XML 缓冲区，并附加 <clienttype>1</clienttype>。

服务端回应：  一个简单的确认报文。（代码中未严格验证回应内容，这是一个潜在弱点）

b.文件传输阶段（针对每个文件）

元数据报文：

客户端发送： <filename>/path/file</filename><mtime>20231010</mtime><size>1024</size>

目的： 告知服务器即将传输的文件信息。

数据报文：

客户端发送： 将文件内容分块（每次 1000 字节）直接通过 TCP 流发送。

注意： 这里没有额外的协议头，服务器需要依靠 size 字段来判断数据何时结束。这是一种简单有效的流式传输方式。

确认 (ACK) 报文：

服务端发送： <filename>/path/file</filename><result>ok</result> (或其它错误信息)

客户端处理 (ackmessage): 根据 result 和 ptype 决定是删除文件还是移动到备份目录。

c.心跳阶段

客户端发送： <activetest>ok</activetest>

服务端回应： 任意内容（只需确认连接通畅）。

4. 文件传输机制 (sendfile 函数)

分块读取和发送： 使用固定大小（1000 字节）的缓冲区循环读取文件并发送，内存使用效率高，适用于大文件。

二进制模式： 以 ios::binary 模式打开文件，确保任何格式的文件都能被正确传输。

5. 流量控制与可靠性 (delayed 变量)

这是客户端实现简单流量控制和保证可靠性的关键机制：

delayed 计数器记录已发送但未收到确认的文件数量。

每成功发送一个文件，delayed++。

每收到一个确认报文，delayed-- 并处理对应文件。

在循环内部 (while (delayed > 0)) 和结束后都会尝试读取确认报文。

作用：
- 防止淹没对端： 避免客户端在未收到确认时无限制地发送文件，给服务器造成过大压力。
- 保证处理顺序： 确保每个文件的确认都能得到及时处理。
- 增强健壮性： 如果连接中断，所有已发送但未确认的文件将在下次运行时重传（因为它们仍然存在于本地目录中）。

# tcpgetfiles

采用tcp协议，实现文件下载的客户端。

## 核心工作流程

- 初始化：解析参数、连接服务器、登录认证。
- 循环等待：
阻塞读取服务器发送的报文，设置读取超时。
判断报文类型：
心跳报文 : 回复确认，保持连接活跃。
文件下载指令 : 解析指令，接收文件内容，保存到本地，并向服务器发送下载结果确认。
- 退出：当网络读取出错或连接断开时，程序退出。

## 关键组件分析

1. 参数结构 (st_arg)

clienttype: 固定为2，表明是下载客户端。

srvpath & andchild & matchname: 定义了服务器上被下载文件的来源（这些参数主要用于服务器端筛选文件，客户端通过登录报文传递给服务器）。

clientpath: 文件下载到客户端的哪个目录。

ptype & srvpathbak: 定义了文件成功下载后，服务器端如何处理源文件（删除或备份）。这个处理是由服务器根据客户端的配置执行的。

timetvl, timeout, pname: 功能同上传客户端。

2. 协议设计与工作模式

tcpputfiles (上传): 客户端主动。客户端扫描目录 -> 主动发送文件 -> 服务器接收并回应。

tcpgetfiles (下载): 服务器主动。客户端等待 -> 服务器发送文件指令 -> 客户端接收并回应。

a.登录阶段

b.主循环 - 等待指令

客户端设置一个读取超时（略大于扫描间隔timetvl），阻塞等待服务器发送任何报文。

服务器发送的报文有两种：

心跳报文 : 由服务器定时发起，用于保活。客户端只需回复 ok。

文件下载请求报文: 当服务器扫描到有文件需要下载时，会向客户端发送一个包含文件元数据的指令。

客户端处理下载请求:

解析元数据： 报文中的 filename、mtime、size。

生成本地路径： 将服务器路径 srvpath 替换为本地路径 clientpath，得到文件将保存的本地位置。

接收文件内容： 调用 recvfile 函数，根据 size 循环读取网络数据并写入本地文件。

发送结果ACK：

服务器根据这个ACK结果决定是否执行ptype操作（删除或移动服务器上的源文件）。

c.recvfile 函数

负责接收文件数据流。

采用分块接收（1000字节）的方式，内存效率高。

使用 cofile 类写入文件，支持创建中间临时文件并在写入完成后原子性地重命名，避免了下载一半的文件被误读。

下载完成后，使用 setmtime 设置本地文件的修改时间，与服务器端文件保持一致。

# fileserver

文件传输的服务端。

## 关键组件

1. 参数结构体 (st_arg)

- 客户端类型，1-上传文件；2-下载文件
- 本地文件存放的根目录
- 文件上传成功后本地文件的处理方式
- 是否处理子目录文件
- 文件匹配规则
- 服务端文件存放的根目录
- 服务端文件备份目录
- 扫描目录的时间间隔
- 进程心跳的超时时间
- 进程名

2. 核心函数

recvfilesmain(): 处理文件上传的主函数

sendfilesmain(): 处理文件下载的主函数

clientlogin(): 处理客户端登录报文

recvfile(): 接收文件内容

sendfile(): 发送文件内容

ackmessage(): 处理文件传输的响应报文

activetest(): 心跳测试

_tcpputfiles(): 执行文件下载任务

## 核心工作流程

1. 初始化阶段

2. 多进程处理

父进程负责接受客户端连接

子进程负责处理具体的文件传输业务

使用fork()创建子进程处理每个客户端连接

3. 客户端登录处理 (clientlogin)

接收客户端的登录报文

解析登录参数并验证客户端类型

发送登录响应报文

设置进程心跳

4. 文件上传流程 (recvfilesmain)

接收客户端的上传请求报文

解析文件名、修改时间和文件大小

生成服务端文件名（路径转换）

接收文件内容并保存到服务端

设置文件的修改时间

发送确认报文给客户端

5. 文件下载流程 (sendfilesmain)

扫描服务端目录，获取文件列表

遍历文件列表，发送文件信息给客户端

发送文件内容给客户端

接收客户端的确认报文

根据确认结果处理服务端文件（删除或移动到备份目录）

6. 心跳机制

定期发送心跳报文保持连接活跃

检测连接状态并及时处理断开情况

# dminingoracle

数据中心的公共功能模块，用于从Oracle数据库源表抽取数据，生成xml文件。

全量抽取：

这次拿到的数据可能会和上次拿到的数据重复。

表中的数据可能会修改。

增量抽取：

每次拿到的数据都是新插入的数据，不会重复。

表中的数据只会新增，不会修改。

数据源表可分为三种:

数据量小，增改删。全量抽取

数据量大，增改。全量抽取

数据量极大，增。增量抽取

每个表必须要有时间戳（全量）和记录编号（增量）。

大表的数据不能有删除，避免修改。

## 关键组件

1. 参数结构体 (st_arg)

- 数据库的连接参数
- 数据库的字符集
- 从数据源数据库抽取数据的SQL语句
- 抽取数据的SQL语句输出结果集字段名
- 抽取数据的SQL语句输出结果集字段的长度
- 输出xml文件的前缀
- 输出xml文件的后缀
- 输出xml文件存放的目录
- 输出xml文件最大记录数
- 程序运行的时间区间
- 递增字段名
- 已抽取数据的递增字段最大值存放的文件
- 已抽取数据的递增字段最大值存放的数据库的连接参数
- 进程心跳的超时时间
- 进程名

这个结构体定义了数据抽取的所有配置参数。

2. 核心函数

_dminingoracle(): 数据抽取的主业务逻辑

readincfield(): 读取增量字段的最大值

writeincfield(): 写入增量字段的最大值

instarttime(): 判断当前时间是否在允许运行的时间区间内

_xmltoarg(): 解析XML格式的配置参数

EXIT(): 进程退出函数，负责资源清理

## 核心工作流程

1. 初始化阶段

2. 数据抽取流程 (_dminingoracle函数)

a.准备SQL语句:

使用预编译的SQL语句

如果是增量抽取，绑定输入参数（已抽取数据的递增字段的最大值）

b.绑定结果集变量:

根据字段长度数组绑定输出变量

支持动态字段映射

c.执行SQL查询:

执行抽取数据的SQL语句

更新进程心跳

d.处理结果集并生成XML文件:

遍历结果集中的每一行记录

将每个字段的值写入XML文件

控制每个XML文件的记录数（通过maxcount参数）

使用临时文件机制确保文件写入的原子性

e.更新增量字段的最大值:

如果是增量抽取，更新递增字段的最大值

将更新后的最大值保存到文件或数据库

3. 增量抽取机制

通过readincfield()函数读取上次抽取的增量字段最大值

通过writeincfield()函数保存本次抽取的增量字段最大值

支持文件和数据库两种方式存储增量字段最大值

4. 时间控制

通过instarttime()函数检查当前时间是否在允许运行的时间区间内

通常在业务低峰期执行数据抽取操作，减少对数据库性能的影响

# xmltodb.cpp

共享平台的公共功能模块，用于把xml文件入库到Oracle的表中。

适用于各种有数据入库需求的项目，可以为不同格式的数据文件编写不同的程序，把它们转化为xml。

如果入库的文件太多，有些文件比较大，入库不及时，可以配置多个入库参数文件，启动多个入库模块。同一种数据使用同一个入库模块，避免多进程操作同一张表。

## 核心数据结构

1. st_arg： 存储程序运行的全局参数。

- connstr, charset： 数据库连接参数。
- inifilename： 核心规则配置文件路径，定义了不同 XML 如何对应不同表。
- xmlpath, xmlpathbak, xmlpatherr： 分别存放待处理、已处理备份、处理失败的 XML 文件的目录。
- timetvl： 处理间隔，体现了其作为守护进程的特性。
- pname： 进程名，用于心跳检测。

2. st_xmltotable 和 vxmltotable： 存储从 inifilename 加载的业务规则。这是程序灵活性的关键。

- filename： XML 文件名匹配规则（支持通配符）。
- tname： 目标数据库表名。
- uptbz： 更新标志（1=存在则更新，2=仅插入不存在记录）。
- execsql： 处理 XML 前执行的 SQL 语句（可用于清理临时表等）。

## 关键模块与函数分析

1. 主循环 (_xmltodb())

这是程序的调度中心，实现了一个生产者-消费者模型：

- 生产者： dir.opendir() 和 dir.readdir()，定期扫描 starg.xmlpath 目录，产生待处理的 XML 文件列表。
- 消费者： _xmltodb(fullfilename, filename) 函数，消费（处理）每一个 XML 文件。
- 心跳： pactive.uptatime() 在关键点更新心跳，防止程序被监控系统误杀。
- 休眠： 当没有文件处理时，睡眠 starg.timetvl 秒，避免空耗 CPU。

2. 单文件处理核心 (_xmltodb(const string&, const string&))
这是业务逻辑的核心，处理一个 XML 文件的完整流程如下：

1. 查找规则 (findxmltotable): 根据当前 XML 文件名，从 vxmltotable 容器中找到匹配的入库规则 (stxmltotable)。
2. 获取表结构 (tcols.allcols(), tcols.pkcols()): 连接到数据库，查询目标表的所有字段 (m_vallcols) 和主键信息 (pkseq)。这是实现动态 SQL 的基础。
3. 拼接 SQL (crtsql()): 基于表结构动态生成两条 SQL 语句：
- strinsertsql: 完整的 INSERT 语句。
- strupdatesql (如果 uptbz==1)： 完整的 UPDATE 语句。SET 部分包含非主键字段，WHERE 部分包含所有主键字段。
4. 准备语句和绑定变量 (preparesql()):
- 为存储字段值的数组 vcolvalue 分配内存。
- 创建 sqlstatement 对象 (stmtins, stmtupt)。
- 将 vcolvalue 数组的每个元素与 SQL 语句中的占位符 (:1, :2...) 进行绑定。这里非常重要，它避免了 SQL 注入风险并提高了性能。
5. 执行前导 SQL (execsql()): 如果规则中配置了 execsql，则在此执行。
6. 读取和解析 XML 文件:
- 逐行读取 XML 文件（每行应为一条完整记录，如 <obtid>58015</obtid>...<keyid>6127135</keyid>）。
- splitbuffer(): 解析每一行。使用 getxmlbuffer 根据字段名提取值，并对 date 和 number 类型进行清洗（提取纯数字字符）。
- 将解析出的值存入 vcolvalue 数组。由于之前已经绑定了变量，vcolvalue 中的值就是即将执行的 SQL 的参数。
7. 执行 SQL:
- 首先尝试 stmtins.execute() (插入)。
- 如果插入失败且错误是唯一性约束冲突 (rc() == 1) 且 规则允许更新 (uptbz == 1)，则执行 stmtupt.execute() (更新)。
- 处理成功则计数 (inscount, uptcount)。
- 处理失败则写日志。如果是数据库连接类严重错误，则返回错误码终止程序。
8. 提交与文件移动: 处理完一个文件中的所有记录后，提交事务 (conn.commit())，并根据处理结果将文件移动到备份或错误目录 (xmltobakerr)。


# deletetable

共享平台的公共功能模块，用于清理表中的数据。如果直接删除全部数据会产生大事务，冲击数据库系统。因此需要分批删除。

## 关键组件

参数结构 (st_arg)：
- 数据库连接参数，格式：username/passwd@tnsname
- 待清理的表名
- 待清理表的唯一键字段名（建议用rowid）
- 待清理数据需满足的条件（SQL中where部分）
- 一次SQL删除的记录数（建议100-500）
- 程序运行的时间区间（如"02,13"）
- 程序超时时间（秒）
- 进程名

## 核心工作流程

程序主要完成以下功能：

a.​​时间判断​​。根据配置的时间区间决定是否执行清理操作。

​b.分批删除​​。

1. 查询符合条件记录的唯一键值。
2. 采用“每批查询一批唯一键，再按批删除”的策略。
3. 使用 IN子句进行批量删除，例如 DELETE FROM table WHERE key IN (...)。
4. ​日志与超时处理​​：记录操作日志，并支持进程心跳更新以监控超时。

# migratetable

用于迁移表中的数据。比如，将若干天前的数据转到历史表中。

## 关键组件

1. 参数结构体 (st_arg)

- 数据库的连接参数
- 待迁移的表名
- 目的表名
- 待迁移的表的唯一键字段名
- 待迁移的数据需要满足的条件
- 执行一次SQL删除的记录数
- 程序运行的时间区间
- 本程序运行时的超时时间
- 本程序运行时的程序名

这个结构体定义了数据迁移的所有配置参数。

2. 核心函数

_migratetable(): 数据迁移的主业务逻辑

instarttime(): 判断当前时间是否在允许运行的时间区间内

_xmltoarg(): 解析XML格式的配置参数

EXIT(): 进程退出函数，负责资源清理

## 核心工作流程

1. 初始化阶段

解析命令行参数和XML配置

检查当前时间是否在允许运行的时间区间内

连接数据库

设置进程心跳

2. 数据迁移流程 (_migratetable函数)

准备SQL语句:

查询语句: 从源表中选择满足条件的唯一键值

删除语句: 从源表中删除已迁移的数据

插入语句: 将数据插入到目标表

分批处理数据:

使用maxcount参数控制每批处理的记录数

通过唯一键值数组绑定SQL参数

先插入到目标表，再从源表删除，确保数据不丢失

事务管理:

每批处理完成后提交事务

确保插入和删除操作的原子性

性能监控:

使用计时器记录迁移操作的执行时间

记录迁移的记录数和耗时

3. 时间控制

通过instarttime()函数检查当前时间是否在允许运行的时间区间内

通常在业务低峰期执行数据迁移操作，减少对数据库性能的影响

# syncref

共享平台的公共功能模块，采用刷新的方法同步Oracle数据库之间的表。

它提供了两种同步策略：

不分批刷新：适用于数据量不大（百万行以下）的情况，一次性完成同步。

分批刷新：适用于大数据量（超过百万行）的情况，分批次进行同步。

增量刷新：数据量很大。

不使用链路，避免远程事务。

## 核心数据结构

st_arg 结构体包含了程序运行所需的所有参数：

数据库连接信息（本地和远程）

表名和字段映射

同步条件和方式

分批处理参数

超时和进程名设置

## 主要功能模块

1. 参数解析 (_xmltoarg)

从XML格式的输入参数中解析出程序运行所需的各项配置

验证参数的完整性和合理性

为缺失的字段列表参数自动填充本地表的全部字段

2. 同步处理 (_syncref)

这是程序的核心功能，根据同步类型分为两种处理方式：

2.1 不分批刷新 (synctype=1)

```
-- 先删除本地表数据
DELETE FROM 本地表 WHERE 条件;

-- 再从远程表插入数据
INSERT INTO 本地表(字段列表) 
SELECT 字段列表 FROM 远程表@dblink WHERE 条件;
```

这种方式简单直接，适用于数据量不大的场景。

2.2 分批刷新 (synctype=2)
这种方式更加复杂，适用于大数据量的同步：

连接到远程数据库

查询需要同步的记录键值

分批次处理：

准备删除和插入的SQL语句，使用IN条件

每批处理最多maxcount条记录

执行删除和插入操作

提交事务

处理剩余不足一批的记录

# syncinc

共享平台的公共功能模块，采用增量的方法同步Oracle数据库之间的表。

## 关键组件

1. 参数结构体 (st_arg)
包含了程序运行所需的所有配置信息：

数据库连接信息（本地和远程）

表名和字段映射关系

同步条件和过滤规则

自增字段配置（用于确定同步的起始点）

分批处理参数

时间间隔和超时设置

2. 数据库连接对象
connection connloc: 本地数据库连接

connection connrem: 远程数据库连接

3. 全局变量
long maxkeyvalue: 存储本地表自增字段的最大值，用于确定需要同步哪些新记录

4. 核心函数
_syncinc(): 增量同步的主业务逻辑

loadmaxkey(): 加载本地表自增字段的最大值

_xmltoarg(): 解析XML格式的配置参数

## 核心工作流程
1. 初始化阶段
解析命令行参数和XML配置

连接本地和远程数据库

自动填充字段列表（如果配置为空）

进入主循环，定期执行同步任务

2. 增量同步流程 (_syncinc函数)
获取同步基准点:

调用loadmaxkey()获取本地表自增字段的最大值

这个值决定了需要同步哪些新记录（只同步ID大于此值的记录）

查询需要同步的记录:

在远程表中查询自增字段值大于本地最大值的记录

使用ROWID作为唯一标识符

可以附加额外的过滤条件(where参数)

分批处理记录:

使用ROWID列表构建IN查询条件

每批处理最多maxcount条记录

通过dblink从远程表查询数据并插入到本地表

提交事务和更新状态:

每批处理完成后提交事务

更新进程心跳

记录同步统计信息

3. 循环执行
如果本次同步处理了数据(bcontinue=true)，立即进行下一次同步

如果没有处理数据(bcontinue=false)，休眠指定时间间隔(timetvl)

持续更新进程心跳，确保程序活跃性

# inetd

正向网络代理服务程序。

## 关键组件

1. 代理路由参数结构体 (st_route)

- 源端口（本地监听端口）
- 目标主机的地址（远程主机地址）
- 目标主机的端口（远程主机端口）
- 源端口监听的socket

这个结构体定义了代理路由的基本参数，包括本地监听端口和远程目标地址信息。

1. 全局变量

vroute: 代理路由的容器，存储所有路由配置

epollfd: epoll的句柄，用于多路I/O复用

clientsocks: 存放每个socket连接对端的socket值

clientatime: 存放每个socket连接最后一次收发报文的时间

clientbuffer: 存放每个socket发送内容的缓冲区

2. 核心函数
loadroute(): 加载代理路由参数配置文件

initserver(): 初始化服务端的监听端口

conntodst(): 向目标地址和端口发起socket连接

EXIT(): 进程退出函数，负责资源清理

main(): 程序主函数，实现正向代理的核心逻辑

##  核心工作流程
1. 初始化阶段

解析命令行参数（日志文件、配置文件）

关闭不必要的信号和输入输出

打开日志文件

加载代理路由参数配置文件

初始化监听socket（为每个路由规则创建监听socket）

创建epoll实例并添加监听socket

2. 主事件循环

程序进入无限循环，使用epoll监听多个文件描述符的事件：

2.1 监听socket事件处理
当本地有新的客户端连接时，accept新的连接

向目标服务器发起连接

将本地客户端和远程服务器的socket配对并添加到epoll监听

更新连接状态数组

2.2 数据通道事件处理

读事件处理:

从一端socket读取数据

将数据追加到对端socket的缓冲区

修改对端socket的事件为可读可写

更新连接的活动时间

写事件处理:

将缓冲区中的数据发送出去

删除已成功发送的数据

如果缓冲区为空，取消写事件监听

3. 连接管理
使用三个全局数组管理所有连接状态

正确处理连接断开的情况

4. 配置文件解析

从INI格式的配置文件中读取代理路由规则

支持注释（#号开头）

处理空格和格式问题

# rinetd

反向网络代理服务程序-外网端。

## 关键组件

1. 代理路由参数结构体 (st_route)

- 源端口（外网监听端口）
- 目标主机的地址（内网服务地址）
- 目标主机的端口（内网服务端口）
- 监听源端口的socket

这个结构体定义了代理路由的基本参数，包括外网监听端口和内网服务地址信息。

1. 全局变量

vroute: 代理路由的容器，存储所有路由配置

epollfd: epoll的句柄，用于多路I/O复用

tfd: 定时器的句柄，用于定期任务

clientsocks: 存放每个socket连接对端的socket值

clientatime: 存放每个socket连接最后一次收发报文的时间

clientbuffer: 存放每个socket发送内容的缓冲区

cmdlistensock: 命令通道监听的socket

cmdconnsock: 命令通道连接的socket

3. 核心函数

loadroute(): 加载代理路由参数配置文件

initserver(): 初始化服务端的监听端口

EXIT(): 进程退出函数，负责资源清理

main(): 程序主函数，实现反向代理的核心逻辑

## 核心工作流程

1. 初始化阶段

解析命令行参数（日志文件、配置文件、命令端口）

关闭不必要的信号和输入输出

打开日志文件

加载代理路由参数配置文件

初始化命令通道的监听端口并等待内网程序连接

初始化外网监听socket（为每个路由规则创建监听socket）

创建epoll实例并添加监听socket和定时器

2. 主事件循环

程序进入无限循环，使用epoll监听多个文件描述符的事件：

2.1 定时器事件处理

每20秒触发一次定时器事件

重新开始计时

向命令通道发送心跳报文(<activetest>)给内网程序

清理空闲超过80秒的客户端连接

2.2 外网监听socket事件处理

当外网有新的客户端连接时，accept新的连接

通过命令通道向内网程序发送命令，包含目标地址和端口信息

等待内网程序连接（阻塞accept）

将外网客户端和内网程序的socket配对并添加到epoll监听

更新连接状态数组

2.3 数据通道事件处理

读事件处理:

从一端socket读取数据

将数据追加到对端socket的缓冲区

修改对端socket的事件为可读可写

更新连接的活动时间

写事件处理:

将缓冲区中的数据发送出去

删除已成功发送的数据

如果缓冲区为空，取消写事件监听

3. 连接管理

使用三个全局数组管理所有连接状态

定期清理空闲连接

正确处理连接断开的情况

4. 配置文件解析

从INI格式的配置文件中读取代理路由规则

支持注释（#号开头）

处理空格和格式问题

# rinetdin

反向网络代理服务程序-内网端。

## 关键组件

1. 全局变量

cmdconnsock: 内网程序与外网程序的命令通道的socket

epollfd: epoll的句柄，用于多路I/O复用

tfd: 定时器的句柄，用于定期清理空闲连接

clientsocks: 存放每个socket连接对端的socket值

clientatime: 存放每个socket连接最后一次收发报文的时间

clientbuffer: 存放每个socket发送内容的缓冲区

2. 核心函数

conntodst(): 向目标IP和端口发起socket连接

EXIT(): 进程退出函数，负责清理资源

main(): 程序主函数，实现反向代理的核心逻辑

## 核心工作流程

1. 初始化阶段
解析命令行参数（日志文件、外网代理程序IP和端口）

关闭不必要的信号和输入输出

打开日志文件

建立与外网程序的命令通道（初始为阻塞模式，后改为非阻塞）

创建epoll实例并添加命令通道socket

创建定时器并添加到epoll

2. 主事件循环

程序进入无限循环，使用epoll监听多个文件描述符的事件：

2.1 定时器事件处理

每20秒触发一次定时器事件

重新开始计时

清理空闲超过80秒的客户端连接

2.2 命令通道事件处理

读取外网程序发送的命令

忽略心跳报文(<activetest>)

处理新建连接命令：

解析目标服务器地址和端口

向外网程序发起连接(srcsock)

向目标服务器发起连接(dstsock)

将两个socket配对并添加到epoll监听

更新连接状态数组

2.3 数据通道事件处理

读事件处理:

从一端socket读取数据

将数据追加到对端socket的缓冲区

修改对端socket的事件为可读可写

更新连接的活动时间

写事件处理:

将缓冲区中的数据发送出去

删除已成功发送的数据

如果缓冲区为空，取消写事件监听

3. 连接管理

使用三个全局数组管理所有连接状态

定期清理空闲连接

正确处理连接断开的情况

4. 数据转发机制

采用缓冲机制处理可能的数据积压

非阻塞I/O确保高性能

精确的事件管理（只在需要时监听写事件）

# webserver

数据访问接口模块。

## 核心架构与设计模式

该程序采用了 主从 Reactor 多线程模型 的变体，职责划分清晰：
- 接收线程 (recvfunc)：主 Reactor，负责监听端口、接受新连接、读取请求数据（I/O 操作）。
- 工作线程 (workfunc)：线程池，负责核心业务逻辑（计算操作）：解析请求、验证权限、执行数据库查询、生成响应报文。
- 发送线程 (sendfunc)：主 Reactor，负责将响应数据写回客户端（I/O 操作）。

线程间通过生产者-消费者模型和消息队列进行通信，使用互斥锁 (mutex) 和条件变量 (condition_variable) 进行同步。

## 关键组件分析

1. 数据结构

- st_client： 维护每个客户端连接的状态（状态机），包括 IP、活动时间、接收缓冲区和发送缓冲区。这是处理粘包和非阻塞 I/O 的关键。
- st_recvmesg： 消息单元，包含客户端 socket 和待处理/待发送的完整报文。使用 shared_ptr 管理生命周期，安全地在线程间传递。
- AA 类： 核心管理类，封装了所有共享资源和线程函数。

m_rq, m_sq： 接收队列和发送队列。

clientmap： 所有客户端状态的哈希表，是共享资源，需加锁访问。

m_sendpipe, m_recvpipe： 用于线程间通知的无名管道。这是将 I/O 事件（队列非空）融入 epoll 事件循环的巧妙设计。

m_exit： 原子变量，用于安全地通知所有线程退出。

2. 线程功能详解

a.接收线程 (recvfunc)

I/O 模型： 使用 epoll 监听多个文件描述符（监听 socket、管道、客户端连接）。

核心职责：

- 接受新连接，将其设为非阻塞模式并加入 epoll 监听。
- 读取客户端数据，并追加到对应 st_client 的 recvbuffer 中。
- 判断是否收到一个完整的 HTTP 请求（以 \r\n\r\n 结尾）。
- 如果收到完整请求，将其封装为 st_recvmesg 并放入接收队列 (inrq)，然后通知工作线程处理。
- 处理超长请求，断开连接以防攻击。
- 监听退出管道，收到退出信号后清理资源。

b.工作线程 (workfunc) - 核心业务

数据库连接： 每个工作线程独立持有一个到 Oracle 的数据库连接 (connection conn)，避免了多线程共用一个连接的复杂性。

核心职责：

- 从接收队列中获取一个请求报文（消费者）。
- 调用 bizmain 函数处理业务逻辑。
- 将 bizmain 返回的 XML 数据包装成完整的 HTTP 响应报文。
- 将响应报文放入发送队列 (insq)，并通过管道通知发送线程。

bizmain 函数是业务核心：
1. 权限验证： 从 T_USERINFO 表验证用户名/密码。
2. IP 绑定： (代码略) 验证客户端 IP 是否在白名单内。
3. 接口权限： 查询 T_USERANDINTER 表判断用户是否有权访问指定接口 (intername)。
4. 获取SQL配置： 从 T_INTERCFG 表加载接口对应的 SQL 语句、输出列和输入参数。
5. 动态SQL执行：

解析 HTTP 请求中的参数，绑定到 SQL 的输入变量 (bindin)。

执行 SQL，将输出列绑定到结果集数组。

遍历结果集，动态拼接成 XML 格式的响应内容。

日志记录： (代码略) 记录接口调用日志。

c.发送线程 (sendfunc)

I/O 模型： 同样使用 epoll，主要监听通知管道和可写的客户端 socket。

核心职责：

监听管道，当工作线程放入新响应时被唤醒。

从发送队列中取出所有响应报文，将其追加到对应 st_client 的 sendbuffer 中。

关注那些 sendbuffer 不为空的客户端 socket 的可写事件 (EPOLLOUT)。

当 socket 可写时，将 sendbuffer 中的数据发送出去。

如果数据全部发送完毕，则取消关注可写事件；如果只发送了一部分，则剩余数据留在 sendbuffer 中，下次可写时继续发送。这是处理写缓冲区满的标准做法。

3. HTTP 协议处理

请求解析： 在接收线程中判断请求结束标志 (\r\n\r\n)，在工作线程中使用 getvalue 函数从请求行中解析出参数（如 username=wucz&passwd=wuczpwd）。

响应组装： 生成标准的 HTTP 响应头（状态行、Server、Content-Type、Content-Length）和 XML 格式的响应体。
